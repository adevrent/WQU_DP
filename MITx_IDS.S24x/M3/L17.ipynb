{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=4, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    V_next = [ 4.  3. -1.]\n",
      "V_old at t=1: [0. 0. 0.]\n",
      "V at t=1: [ 4.  3. -1.]\n",
      "    V_next = [5.6 2.9 0.1]\n",
      "V_old at t=2: [ 4.  3. -1.]\n",
      "V at t=2: [5.6 2.9 0.1]\n",
      "    V_next = [5.72 3.33 0.17]\n",
      "V_old at t=3: [5.6 2.9 0.1]\n",
      "V at t=3: [5.72 3.33 0.17]\n",
      "    V_next = [5.904 3.401 0.349]\n",
      "V_old at t=4: [5.72 3.33 0.17]\n",
      "V at t=4: [5.904 3.401 0.349]\n",
      "    V_next = [5.9508 3.4797 0.3953]\n",
      "V_old at t=5: [5.904 3.401 0.349]\n",
      "V at t=5: [5.9508 3.4797 0.3953]\n",
      "    V_next = [5.987  3.5061 0.4314]\n",
      "V_old at t=6: [5.9508 3.4797 0.3953]\n",
      "V at t=6: [5.987  3.5061 0.4314]\n",
      "    V_next = [6.0011 3.5232 0.4456]\n",
      "V_old at t=7: [5.987  3.5061 0.4314]\n",
      "V at t=7: [6.0011 3.5232 0.4456]\n",
      "    V_next = [6.0094 3.5305 0.4538]\n",
      "V_old at t=8: [6.0011 3.5232 0.4456]\n",
      "V at t=8: [6.0094 3.5305 0.4538]\n",
      "    V_next = [6.0132 3.5346 0.4576]\n",
      "V_old at t=9: [6.0094 3.5305 0.4538]\n",
      "V at t=9: [6.0132 3.5346 0.4576]\n",
      "    V_next = [6.0151 3.5365 0.4596]\n",
      "V_old at t=10: [6.0132 3.5346 0.4576]\n",
      "V at t=10: [6.0151 3.5365 0.4596]\n",
      "    V_next = [6.0161 3.5375 0.4606]\n",
      "V_old at t=11: [6.0151 3.5365 0.4596]\n",
      "V at t=11: [6.0161 3.5375 0.4606]\n",
      "    V_next = [6.0166 3.538  0.4611]\n",
      "V_old at t=12: [6.0161 3.5375 0.4606]\n",
      "V at t=12: [6.0166 3.538  0.4611]\n",
      "    V_next = [6.0168 3.5382 0.4613]\n",
      "V_old at t=13: [6.0166 3.538  0.4611]\n",
      "V at t=13: [6.0168 3.5382 0.4613]\n",
      "    V_next = [6.017  3.5383 0.4614]\n",
      "V_old at t=14: [6.0168 3.5382 0.4613]\n",
      "V at t=14: [6.017  3.5383 0.4614]\n",
      "    V_next = [6.017  3.5384 0.4615]\n",
      "V_old at t=15: [6.017  3.5383 0.4614]\n",
      "V at t=15: [6.017  3.5384 0.4615]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.017 , 3.5384, 0.4615])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([0, 1, 2])  # state space (low/moderate/high)\n",
    "U = np.array([0, 1])  # action space (buy/sell)\n",
    "\n",
    "# Construct state space, action, probability matrix,\n",
    "# depth index is ACTION, Row index is state FROM, col index is state TO\n",
    "P = np.array([\n",
    "    [\n",
    "        [0.2, 0.8, 0.0],\n",
    "        [0.0, 0.2, 0.8],\n",
    "        [0.0, 0.2, 0.8]\n",
    "    ],\n",
    "    [\n",
    "        [0.8, 0.2, 0.0],\n",
    "        [0.8, 0.2, 0.0],\n",
    "        [0.0, 0.8, 0.2]\n",
    "    ]\n",
    "])\n",
    "\n",
    "# Immediate rewards, rows are states, cols are actions\n",
    "G = np.array([\n",
    "    [4, -1],\n",
    "    [3, -1],\n",
    "    [2, -1]\n",
    "])\n",
    "\n",
    "gamma = 0.5  # discount factor\n",
    "\n",
    "def update_V(V, gamma=0.5):\n",
    "    # print(\"V.shape =\", V.shape)\n",
    "    policy = []\n",
    "    V_next = V.copy()\n",
    "    for x in range(V.shape[0]):\n",
    "        future_expected_reward = (P[:, x, :] @ V)  # shape (2,)\n",
    "        opt_u = np.argmax(gamma * future_expected_reward + G[x, :])\n",
    "        policy.append(opt_u)\n",
    "        V_next[x] = G[x, opt_u] + gamma * future_expected_reward[opt_u]\n",
    "    print(\"    V_next =\", V_next)\n",
    "    return V_next, policy\n",
    "\n",
    "def fixed_policy_update_V(V, policy_dict, gamma=0.5):\n",
    "    # print(\"V.shape =\", V.shape)\n",
    "    V_next = V.copy()\n",
    "    for x in range(V.shape[0]):\n",
    "        future_expected_reward = (P[:, x, :] @ V)  # shape (2,)\n",
    "        fixed_u = policy_dict[x]\n",
    "        V_next[x] = G[x, fixed_u] + gamma * future_expected_reward[fixed_u]\n",
    "    print(\"    V_next =\", V_next)\n",
    "    return V_next\n",
    "\n",
    "def value_iteration(num_states, gamma=0.5, epsilon=1e-4):\n",
    "    V_old = np.zeros(num_states)\n",
    "    V = update_V(V_old, gamma)\n",
    "    t = 1\n",
    "    print(f\"V_old at t={t}:\", V_old)\n",
    "    print(f\"V at t={t}:\", V)\n",
    "    while np.abs(V_old - V).max() > epsilon:\n",
    "        V_old = V.copy()\n",
    "        V = update_V(V, gamma)\n",
    "        t += 1\n",
    "        print(f\"V_old at t={t}:\", V_old)\n",
    "        print(f\"V at t={t}:\", V)\n",
    "    return V\n",
    "\n",
    "def fixed_policy_value_iteration(policy_dict, num_states, gamma=0.5, epsilon=1e-4):\n",
    "    V_old = np.zeros(num_states)\n",
    "    V = fixed_policy_update_V(V_old, policy_dict, gamma)\n",
    "    t = 1\n",
    "    print(f\"V_old at t={t}:\", V_old)\n",
    "    print(f\"V at t={t}:\", V)\n",
    "    while np.abs(V_old - V).max() > epsilon:\n",
    "        V_old = V.copy()\n",
    "        V = fixed_policy_update_V(V, policy_dict, gamma)\n",
    "        t += 1\n",
    "        print(f\"V_old at t={t}:\", V_old)\n",
    "        print(f\"V at t={t}:\", V)\n",
    "    return V\n",
    "\n",
    "num_states = len(X)\n",
    "# value_iteration(num_states)\n",
    "\n",
    "policy_dict = {\n",
    "    0:0,  # L: BUY\n",
    "    1:0,  # M: BUY\n",
    "    2:1   # H: SELL\n",
    "}\n",
    "\n",
    "fixed_policy_value_iteration(policy_dict, num_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0171 3.5385 0.4615]\n",
      "    V_next = [6.0171 3.5385 2.5385]\n",
      "[6.0171 3.5385 2.5385]\n",
      "[0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "T = np.array([\n",
    "    [0.1, 0.4, 0],\n",
    "    [0, 0.1, 0.4],\n",
    "    [0, 0.4, 0.1]\n",
    "])\n",
    "\n",
    "b = np.array([4, 3, -1])[:, np.newaxis]\n",
    "\n",
    "V_mu_0 = (np.linalg.inv(np.eye(T.shape[0]) - T) @ b).flatten()\n",
    "print(V_mu_0)\n",
    "\n",
    "V_new, policy = update_V(V_mu_0)\n",
    "print(V_new)\n",
    "print(policy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
